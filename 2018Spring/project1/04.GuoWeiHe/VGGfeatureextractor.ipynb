{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "CKPT_DIR = './vgg19ckpt/'\n",
    "from dataloader import DataLoader\n",
    "import cv2\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "\n",
    "Please first download all image patches from https://drive.google.com/file/d/1j3GKpZVRqYSa7h5bA7Zp8-sEx62hkUrw/view?usp=sharing and then extract to the current directory.\n",
    "\n",
    "Please download VGG19 pre-trained network from http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz and then extract it to the current directory.\n",
    "\n",
    "Please also download the VGG19-extracted features from https://drive.google.com/file/d/1T8hDmW0-kds4L_m1v_ReUTsmHI5NHeO2/view?usp=sharing and the pre-trained SVM model from https://drive.google.com/file/d/1hV4_qjF-edaQMZEAPAjzwpab2tXkmduR/view?usp=sharing, both put into the directory of this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the computational graph of VGG16 network.\n",
    "class vgg19:\n",
    "    def __init__(self, imgs):\n",
    "        self.imgs = imgs\n",
    "        self.convlayers()\n",
    "        self.fc_layers()\n",
    "        self.probs = tf.nn.softmax(self.fc8l)\n",
    "\n",
    "\n",
    "    def convlayers(self):\n",
    "        self.parameters = []\n",
    "\n",
    "        # zero-mean input\n",
    "        with tf.name_scope('preprocess') as scope:\n",
    "            mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')\n",
    "            images = self.imgs-mean\n",
    "\n",
    "        with tf.name_scope('conv1') as sc:\n",
    "            # conv1_1\n",
    "            with tf.name_scope('conv1_1') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv1_1 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv1_2\n",
    "            with tf.name_scope('conv1_2') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv1_2 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # pool1\n",
    "            self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                                   ksize=[1, 2, 2, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME',\n",
    "                                   name='pool1')\n",
    "\n",
    "\n",
    "        with tf.name_scope('conv2') as sc:\n",
    "            # conv2_1\n",
    "            with tf.name_scope('conv2_1') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv2_1 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv2_2\n",
    "            with tf.name_scope('conv2_2') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv2_2 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # pool2\n",
    "            self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                                   ksize=[1, 2, 2, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME',\n",
    "                                   name='pool2')\n",
    "\n",
    "\n",
    "        with tf.name_scope('conv3') as sc:\n",
    "            # conv3_1\n",
    "            with tf.name_scope('conv3_1') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv3_1 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv3_2\n",
    "            with tf.name_scope('conv3_2') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv3_2 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv3_3\n",
    "            with tf.name_scope('conv3_3') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv3_3 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "                \n",
    "            with tf.name_scope('conv3_4') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv3_3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv3_4 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # pool3\n",
    "            self.pool3 = tf.nn.max_pool(self.conv3_4,\n",
    "                                   ksize=[1, 2, 2, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME',\n",
    "                                   name='pool3')\n",
    "        with tf.name_scope('conv4') as sc:\n",
    "            # conv4_1\n",
    "            with tf.name_scope('conv4_1') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv4_1 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv4_2\n",
    "            with tf.name_scope('conv4_2') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv4_2 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv4_3\n",
    "            with tf.name_scope('conv4_3') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv4_3 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "                \n",
    "            with tf.name_scope('conv4_4') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv4_3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv4_4 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # pool4\n",
    "            self.pool4 = tf.nn.max_pool(self.conv4_4,\n",
    "                                   ksize=[1, 2, 2, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME',\n",
    "                                   name='pool4')\n",
    "\n",
    "\n",
    "        with tf.name_scope('conv5') as sc:\n",
    "            # conv5_1\n",
    "            with tf.name_scope('conv5_1') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv5_1 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv5_2\n",
    "            with tf.name_scope('conv5_2') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv5_2 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # conv5_3\n",
    "            with tf.name_scope('conv5_3') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv5_3 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "                \n",
    "            with tf.name_scope('conv5_4') as scope:\n",
    "                kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "                conv = tf.nn.conv2d(self.conv5_3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "                biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                     trainable=True, name='biases')\n",
    "                out = tf.nn.bias_add(conv, biases)\n",
    "                self.conv5_4 = tf.nn.relu(out, name=scope)\n",
    "                self.parameters += [kernel, biases]\n",
    "\n",
    "            # pool5\n",
    "            self.pool5 = tf.nn.max_pool(self.conv5_4,\n",
    "                                   ksize=[1, 2, 2, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME',\n",
    "                                   name='pool5')\n",
    "\n",
    "    def fc_layers(self):\n",
    "        # fc6\n",
    "        with tf.name_scope('fc6') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([7, 7, 512, 4096], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool5, kernel, [1, 1, 1, 1], padding='VALID')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[4096], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.fc6 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # fc7\n",
    "        with tf.name_scope('fc7') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([1, 1, 4096, 4096], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.fc6, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[4096], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.fc7 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # fc8\n",
    "        with tf.name_scope('fc8') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([1, 1, 4096, 1000], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.fc7, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[1000], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.fc8l = out\n",
    "            self.fc8 = tf.nn.softmax(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "input_img = tf.placeholder(tf.float32,[None,224,224,3])\n",
    "\n",
    "with tf.variable_scope('vgg_19') as scope:\n",
    "    VGGModel = vgg19(imgs=input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vgg_19.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "#Start a TF session, load the vgg_16.ckpt pre-trained model to the variables to initialize them.\n",
    "sess = tf.Session()\n",
    "vars_vgg = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='vgg_19')\n",
    "saver_vgg = tf.train.Saver(max_to_keep=3, var_list=vars_vgg)\n",
    "ckpt_vgg = tf.train.get_checkpoint_state(CKPT_DIR)\n",
    "start_itr = 0\n",
    "# if ckpt_vgg and ckpt_vgg.model_checkpoint_path:\n",
    "saver_vgg.restore(sess, './vgg_19.ckpt')\n",
    "vggfc6feature = tf.squeeze(VGGModel.fc6, axis=[1, 2])\n",
    "print(\"Model restored.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the TensorFlow session to extract FC6 features for all patches\n",
    "You may skip this step is you have downloaded the allfeatures.file binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allfeatures done\n"
     ]
    }
   ],
   "source": [
    "# This step generates image features at the FC6 layer of VGG16.\n",
    "# You may skip this step\n",
    "loader = DataLoader()\n",
    "features = []\n",
    "lists = [loader.yes_image_name, loader.no_image_name]\n",
    "# Run the graph in the session for every image crop.\n",
    "for list in lists:\n",
    "    for yesimg in list:\n",
    "        img = cv2.imread(yesimg)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        feature = sess.run(vggfc6feature,feed_dict={input_img:img})\n",
    "        features.append(feature)\n",
    "\n",
    "# allfeatures is a 2D numpy array of size 6084*4096, meaning 6084 pieces os of crops and each with a 4096-dim vector.\n",
    "allfeatures = np.array(features)\n",
    "allfeatures = np.squeeze(allfeatures)\n",
    "print(\"allfeatures done\")\n",
    "with open ('allfeatures.file','wb') as file:\n",
    "    pickle.dump(allfeatures,file,protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataloader import DataLoader\n",
    "from converter import send_crops_of_this_dispute_painting\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the SVM classifier by the FC6 features and their labels.\n",
    "You may skip the following two steps if you have downloaded svmmodel.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM Done.\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "# Construct the Y-vector for training a simple SVM classifier. Y is a vector with the first 3525 elements being 1\n",
    "# and the rest being 0. \n",
    "y = np.zeros([len(loader.yes_image_name) + len(loader.no_image_name)])\n",
    "y[0:len(loader.yes_image_name)] = 1\n",
    "allfeatures = None\n",
    "with open ('allfeatures.file','rb') as file:\n",
    "    allfeatures = pickle.load(file)\n",
    "\n",
    "# Train the SVM classifier with extracted image features and their corresponding labels.\n",
    "classifier = svm.SVC(probability=True) #\n",
    "classifier.fit(allfeatures, y)\n",
    "print(\"Training SVM Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('svmmodel.file','wb') as file:\n",
    "    pickle.dump(classifier,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You may load a pre-trained SVM model to object 'classifier'\n",
    "classifier = svm.SVC()\n",
    "with open ('svmmodel.file','rb') as file:\n",
    "    classifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions for every crop that represents an image, and sum the score of all crops within a painting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "painting number  1\n",
      "[ 196.17541067  143.82458933]\n",
      "Painting number  1  is fake\n",
      "painting number  7\n",
      "[ 218.7632378  131.2367622]\n",
      "Painting number  7  is fake\n",
      "painting number  10\n",
      "[ 56.08184259  87.91815741]\n",
      "Painting number  10  is real\n",
      "painting number  20\n",
      "[ 4.98140087  7.01859913]\n",
      "Painting number  20  is real\n",
      "painting number  23\n",
      "[ 23.66681448  24.33318552]\n",
      "Painting number  23  is real\n",
      "painting number  25\n",
      "[ 363.42987069  143.57012931]\n",
      "Painting number  25  is fake\n",
      "painting number  26\n",
      "[ 93.15345148  50.84654852]\n",
      "Painting number  26  is fake\n"
     ]
    }
   ],
   "source": [
    "DISPUTE = [1, 7, 10, 20, 23, 25, 26]\n",
    "for i in range(len(DISPUTE)):\n",
    "    testdata = send_crops_of_this_dispute_painting(DISPUTE[i])\n",
    "    print(\"painting number \",DISPUTE[i])\n",
    "    allfeatures_thispainting = []\n",
    "    for j in range(testdata.shape[0]):\n",
    "        features_onecrop = sess.run(vggfc6feature,feed_dict={input_img:testdata[j:j+1,:,:,:]})\n",
    "        allfeatures_thispainting.append(features_onecrop)\n",
    "    pred = classifier.predict_proba(np.squeeze(np.array(allfeatures_thispainting)))\n",
    "    scores = np.sum(pred,axis=0)\n",
    "    print(scores)\n",
    "    if scores[0] > scores[1]:\n",
    "        print(\"Painting number \", DISPUTE[i] ,\" is fake\")\n",
    "    else:\n",
    "        print(\"Painting number \", DISPUTE[i], \" is real\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
